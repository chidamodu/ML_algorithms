{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To estimate model performance by splitting the dataset into training and testing sets using train_test_split\n",
    "\n",
    "irs=load_iris()\n",
    "\n",
    "X=irs.data\n",
    "y=irs.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#The model performance measured via accuracy\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=4)\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#to verify how the testing accuracy varies according to which set of observation been chosen - as obvious it is from the result\n",
    "#the testing accuracy suffers from high variance issues. this is why testing accuracy is known as the high variance estimate\n",
    "#what if we ran the above cell using a random_state=3\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=3)\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Training set Testing set\n",
      "1, [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24], [0 1 2 3 4]\n",
      "2, [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24], [5 6 7 8 9]\n",
      "3, [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24], [10 11 12 13 14]\n",
      "4, [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24], [15 16 17 18 19]\n",
      "5, [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], [20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "#to demonstrate the splitting of a dataset with 25 observations into 5 folds\n",
    "from sklearn.cross_validation import KFold\n",
    "kf=KFold(25, n_folds=5, shuffle=False)\n",
    "\n",
    "#print the contents of each training and testing set\n",
    "print('{} {} {}'.format('Iteration', 'Training set', 'Testing set'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{}, {}, {}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91666667 1.         0.91666667 1.         1.         1.\n",
      " 1.         1.         1.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "#To select the best parameter for KNN via cross validation using the iris dataset\n",
    "#To use only the training data and get X and y for cross validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=3)\n",
    "\n",
    "knn_cv=KNeighborsClassifier(n_neighbors=5)\n",
    "score_cv=cross_val_score(knn_cv, X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.953888888888889, 0.943888888888889, 0.9622222222222222, 0.953888888888889, 0.9722222222222221, 0.9705555555555556, 0.9705555555555556, 0.9705555555555556, 0.9705555555555556, 0.9522222222222224, 0.9705555555555556, 0.9605555555555556, 0.9522222222222222, 0.9605555555555556, 0.9622222222222222, 0.9605555555555556, 0.9622222222222222, 0.9605555555555556, 0.9522222222222222, 0.9431313131313133, 0.9522222222222222, 0.9431313131313133, 0.9431313131313133, 0.9514646464646466, 0.9514646464646466, 0.9431313131313133, 0.9605555555555556, 0.9597979797979799, 0.9605555555555556, 0.943888888888889]\n"
     ]
    }
   ],
   "source": [
    "#now onto searching for an optimal value for K (the number of folds in Kfold)\n",
    "k_val_range=range(1, 31)\n",
    "k_score=[]\n",
    "for element in k_val_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=element)\n",
    "    score=cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    k_score.append(score.mean())\n",
    "print(k_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10747b0b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1074610b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#From the below plot it can be seen that the optimum accuracy is achieved when k ranges from 5 to 9 and at 11. choosing K depends on the situation and the context of business problem. If high variance can be tolerated then we can choose K=11, but if low variance is preferred then we can choose lower values for K in this example K=5 \n",
    "#but regardless of the values for K we are going for high accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plot the cross_validated accuracy on y_axis for every value of k on x_axis\n",
    "plt.plot(k_val_range, k_score)\n",
    "plt.xlabel(\"Value of K for KNN\")\n",
    "plt.ylabel(\"Cross_validated accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705555555555556\n"
     ]
    }
   ],
   "source": [
    "#To select the best model amongst options using cross validation\n",
    "#KNN Vs. logistic regression\n",
    "# Although from cross validation it appeared that KNeighborsClassifier had high accuracy, but after scoring each model on \n",
    "# the test data it is clear that the Logistic Regression has scored high accuracy. Thus the cross validated score may not be the right\n",
    "# representation of the out-of-sample accuracy estimate and it is important to test the accuracy of the models on test data to pick the best model\n",
    "\n",
    "#k-fold cross validation to choose the best approximation to the out-of-sample accuracy using KNN\n",
    "knn_1=KNeighborsClassifier(n_neighbors=11)#I am choosing k=11 from the above cell. although the result is inconclusive, I am going for higher value for K\n",
    "print(cross_val_score(knn_1, X_train, y_train, cv=10, scoring='accuracy').mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447979797979797\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation to choose the best approximation to the out-of-sample accuracy using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "dragon=cross_val_score(logreg, X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(dragon.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To test the Logistic Regression model's performance on the untouched test data\n",
    "\n",
    "#to figure out: what happens after this cross_val_score and also to verify what I have done below by fitting logreg and have found the score is correct or not?\n",
    "alum=logreg.fit(X_train, y_train)\n",
    "\n",
    "alum.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To select the best features using cross validation to fit a model \n",
    "\n",
    "#To decide whether to include the 'newspaper' as a feature in fitting a linear model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df=pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_include=['TV','radio','newspaper']\n",
    "\n",
    "X1=df[col_include]\n",
    "\n",
    "y1=df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1=train_test_split(X1, y1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.64817609 -2.44411865 -7.53220013 -1.64016756 -2.25359703 -3.36652418\n",
      " -2.01211011 -1.02656358 -5.89640739 -2.63707105]\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validation with all the three features in col_include\n",
    "lm=LinearRegression()\n",
    "lm_score=cross_val_score(lm, X_train1, y_train1, cv=10, scoring='neg_mean_squared_error')#it is now neg_mean_squared_error and no more mean_squared_error\n",
    "print(lm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.64817609 2.44411865 7.53220013 1.64016756 2.25359703 3.36652418\n",
      " 2.01211011 1.02656358 5.89640739 2.63707105]\n"
     ]
    }
   ],
   "source": [
    "#To fix the negative signs of MSE score above\n",
    "mse_score=-lm_score\n",
    "print(mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.15596291 1.56336773 2.7444854  1.28069027 1.50119853 1.83480903\n",
      " 1.41848867 1.01319474 2.42825192 1.62390611]\n"
     ]
    }
   ],
   "source": [
    "#convert from mse to rmse(root mean squared value)\n",
    "import numpy as np\n",
    "rmse_score=np.sqrt(mse_score)\n",
    "print(rmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.756435531395855\n"
     ]
    }
   ],
   "source": [
    "#To calculate the average of the rmse_score calculated above\n",
    "print(rmse_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.723583266116106\n"
     ]
    }
   ],
   "source": [
    "#to get another rmse value calculated without using the feature: 'newspaper'\n",
    "\n",
    "#since the goal of calculating rmse score is to reduce error or loss we choose the model with low rmse value and therefore\n",
    "#we pick the second linear regression model(below) that is fitted without the feature: 'newspaper'\n",
    "\n",
    "col_include_outnews=['TV','radio']\n",
    "\n",
    "X11=df[col_include_outnews]\n",
    "\n",
    "y11=df['sales']\n",
    "\n",
    "X_train11, X_test11, y_train11, y_test11=train_test_split(X11, y11, random_state=4)\n",
    "\n",
    "print(np.sqrt(-cross_val_score(lm, X_train11, y_train11, cv=10, scoring='neg_mean_squared_error')).mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to calculate validation error along with training error(here validation error is not same as the test error)\n",
    "#For example, I am going to use the above calculation to find the validation error, which can give an idea about how well\n",
    "#the model can generalize on unseen data and therefore if further tweaking has to be done could be carried out before finding the testing error\n",
    "\n",
    "col_include_outnews=['TV','radio']\n",
    "\n",
    "X11=df[col_include_outnews]\n",
    "\n",
    "y11=df['sales']\n",
    "\n",
    "X_train11, X_test11, y_train11, y_test11=train_test_split(X11, y11, random_state=4)\n",
    "\n",
    "X_train11, X_valid11, y_train11, y_valid11=train_test_split(X_train11, y_train11, random_state=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales\n",
      "0   22.1\n",
      "   sales\n",
      "1   10.4\n",
      "   sales\n",
      "2    9.3\n",
      "   sales\n",
      "3   18.5\n",
      "   sales\n",
      "4   12.9\n",
      "   sales\n",
      "5    7.2\n",
      "   sales\n",
      "6   11.8\n",
      "   sales\n",
      "7   13.2\n",
      "   sales\n",
      "8    4.8\n",
      "   sales\n",
      "9   10.6\n",
      "    sales\n",
      "10    8.6\n",
      "    sales\n",
      "11   17.4\n",
      "    sales\n",
      "12    9.2\n",
      "    sales\n",
      "13    9.7\n",
      "    sales\n",
      "14   19.0\n",
      "    sales\n",
      "15   22.4\n",
      "    sales\n",
      "16   12.5\n",
      "    sales\n",
      "17   24.4\n",
      "    sales\n",
      "18   11.3\n",
      "    sales\n",
      "19   14.6\n",
      "    sales\n",
      "20   18.0\n",
      "    sales\n",
      "21   12.5\n",
      "    sales\n",
      "22    5.6\n",
      "    sales\n",
      "23   15.5\n",
      "    sales\n",
      "24    9.7\n",
      "    sales\n",
      "25   12.0\n",
      "    sales\n",
      "26   15.0\n",
      "    sales\n",
      "27   15.9\n",
      "    sales\n",
      "28   18.9\n",
      "    sales\n",
      "29   10.5\n",
      "    sales\n",
      "30   21.4\n",
      "    sales\n",
      "31   11.9\n",
      "    sales\n",
      "32    9.6\n",
      "    sales\n",
      "33   17.4\n",
      "    sales\n",
      "34    9.5\n",
      "    sales\n",
      "35   12.8\n",
      "    sales\n",
      "36   25.4\n",
      "    sales\n",
      "37   14.7\n",
      "    sales\n",
      "38   10.1\n",
      "    sales\n",
      "39   21.5\n",
      "    sales\n",
      "40   16.6\n",
      "    sales\n",
      "41   17.1\n",
      "    sales\n",
      "42   20.7\n",
      "    sales\n",
      "43   12.9\n",
      "    sales\n",
      "44    8.5\n",
      "    sales\n",
      "45   14.9\n",
      "    sales\n",
      "46   10.6\n",
      "    sales\n",
      "47   23.2\n",
      "    sales\n",
      "48   14.8\n",
      "    sales\n",
      "49    9.7\n",
      "    sales\n",
      "50   11.4\n",
      "    sales\n",
      "51   10.7\n",
      "    sales\n",
      "52   22.6\n",
      "    sales\n",
      "53   21.2\n",
      "    sales\n",
      "54   20.2\n",
      "    sales\n",
      "55   23.7\n",
      "    sales\n",
      "56    5.5\n",
      "    sales\n",
      "57   13.2\n",
      "    sales\n",
      "58   23.8\n",
      "    sales\n",
      "59   18.4\n",
      "    sales\n",
      "60    8.1\n",
      "    sales\n",
      "61   24.2\n",
      "    sales\n",
      "62   15.7\n",
      "    sales\n",
      "63   14.0\n",
      "    sales\n",
      "64   18.0\n",
      "    sales\n",
      "65    9.3\n",
      "    sales\n",
      "66    9.5\n",
      "    sales\n",
      "67   13.4\n",
      "    sales\n",
      "68   18.9\n",
      "    sales\n",
      "69   22.3\n",
      "    sales\n",
      "70   18.3\n",
      "    sales\n",
      "71   12.4\n",
      "    sales\n",
      "72    8.8\n",
      "    sales\n",
      "73   11.0\n",
      "    sales\n",
      "74   17.0\n",
      "    sales\n",
      "75    8.7\n",
      "    sales\n",
      "76    6.9\n",
      "    sales\n",
      "77   14.2\n",
      "    sales\n",
      "78    5.3\n",
      "    sales\n",
      "79   11.0\n",
      "    sales\n",
      "80   11.8\n",
      "    sales\n",
      "81   12.3\n",
      "    sales\n",
      "82   11.3\n",
      "    sales\n",
      "83   13.6\n",
      "    sales\n",
      "84   21.7\n",
      "    sales\n",
      "85   15.2\n",
      "    sales\n",
      "86   12.0\n",
      "    sales\n",
      "87   16.0\n",
      "    sales\n",
      "88   12.9\n",
      "    sales\n",
      "89   16.7\n",
      "    sales\n",
      "90   11.2\n",
      "    sales\n",
      "91    7.3\n",
      "    sales\n",
      "92   19.4\n",
      "    sales\n",
      "93   22.2\n",
      "    sales\n",
      "94   11.5\n",
      "    sales\n",
      "95   16.9\n",
      "    sales\n",
      "96   11.7\n",
      "    sales\n",
      "97   15.5\n",
      "    sales\n",
      "98   25.4\n",
      "    sales\n",
      "99   17.2\n",
      "     sales\n",
      "100   11.7\n",
      "     sales\n",
      "101   23.8\n",
      "     sales\n",
      "102   14.8\n",
      "     sales\n",
      "103   14.7\n",
      "     sales\n",
      "104   20.7\n",
      "     sales\n",
      "105   19.2\n",
      "     sales\n",
      "106    7.2\n",
      "     sales\n",
      "107    8.7\n",
      "     sales\n",
      "108    5.3\n",
      "     sales\n",
      "109   19.8\n",
      "     sales\n",
      "110   13.4\n",
      "     sales\n",
      "111   21.8\n",
      "     sales\n",
      "112   14.1\n",
      "     sales\n",
      "113   15.9\n",
      "     sales\n",
      "114   14.6\n",
      "     sales\n",
      "115   12.6\n",
      "     sales\n",
      "116   12.2\n",
      "     sales\n",
      "117    9.4\n",
      "     sales\n",
      "118   15.9\n",
      "     sales\n",
      "119    6.6\n",
      "     sales\n",
      "120   15.5\n",
      "     sales\n",
      "121    7.0\n",
      "     sales\n",
      "122   11.6\n",
      "     sales\n",
      "123   15.2\n",
      "     sales\n",
      "124   19.7\n",
      "     sales\n",
      "125   10.6\n",
      "     sales\n",
      "126    6.6\n",
      "     sales\n",
      "127    8.8\n",
      "     sales\n",
      "128   24.7\n",
      "     sales\n",
      "129    9.7\n",
      "     sales\n",
      "130    1.6\n",
      "     sales\n",
      "131   12.7\n",
      "     sales\n",
      "132    5.7\n",
      "     sales\n",
      "133   19.6\n",
      "     sales\n",
      "134   10.8\n",
      "     sales\n",
      "135   11.6\n",
      "     sales\n",
      "136    9.5\n",
      "     sales\n",
      "137   20.8\n",
      "     sales\n",
      "138    9.6\n",
      "     sales\n",
      "139   20.7\n",
      "     sales\n",
      "140   10.9\n",
      "     sales\n",
      "141   19.2\n",
      "     sales\n",
      "142   20.1\n",
      "     sales\n",
      "143   10.4\n",
      "     sales\n",
      "144   11.4\n",
      "     sales\n",
      "145   10.3\n",
      "     sales\n",
      "146   13.2\n",
      "     sales\n",
      "147   25.4\n",
      "     sales\n",
      "148   10.9\n",
      "     sales\n",
      "149   10.1\n",
      "     sales\n",
      "150   16.1\n",
      "     sales\n",
      "151   11.6\n",
      "     sales\n",
      "152   16.6\n",
      "     sales\n",
      "153   19.0\n",
      "     sales\n",
      "154   15.6\n",
      "     sales\n",
      "155    3.2\n",
      "     sales\n",
      "156   15.3\n",
      "     sales\n",
      "157   10.1\n",
      "     sales\n",
      "158    7.3\n",
      "     sales\n",
      "159   12.9\n",
      "     sales\n",
      "160   14.4\n",
      "     sales\n",
      "161   13.3\n",
      "     sales\n",
      "162   14.9\n",
      "     sales\n",
      "163   18.0\n",
      "     sales\n",
      "164   11.9\n",
      "     sales\n",
      "165   11.9\n",
      "     sales\n",
      "166    8.0\n",
      "     sales\n",
      "167   12.2\n",
      "     sales\n",
      "168   17.1\n",
      "     sales\n",
      "169   15.0\n",
      "     sales\n",
      "170    8.4\n",
      "     sales\n",
      "171   14.5\n",
      "     sales\n",
      "172    7.6\n",
      "     sales\n",
      "173   11.7\n",
      "     sales\n",
      "174   11.5\n",
      "     sales\n",
      "175   27.0\n",
      "     sales\n",
      "176   20.2\n",
      "     sales\n",
      "177   11.7\n",
      "     sales\n",
      "178   11.8\n",
      "     sales\n",
      "179   12.6\n",
      "     sales\n",
      "180   10.5\n",
      "     sales\n",
      "181   12.2\n",
      "     sales\n",
      "182    8.7\n",
      "     sales\n",
      "183   26.2\n",
      "     sales\n",
      "184   17.6\n",
      "     sales\n",
      "185   22.6\n",
      "     sales\n",
      "186   10.3\n",
      "     sales\n",
      "187   17.3\n",
      "     sales\n",
      "188   15.9\n",
      "     sales\n",
      "189    6.7\n",
      "     sales\n",
      "190   10.8\n",
      "     sales\n",
      "191    9.9\n",
      "     sales\n",
      "192    5.9\n",
      "     sales\n",
      "193   19.6\n",
      "     sales\n",
      "194   17.3\n",
      "     sales\n",
      "195    7.6\n",
      "     sales\n",
      "196    9.7\n",
      "     sales\n",
      "197   12.8\n",
      "     sales\n",
      "198   25.5\n",
      "     sales\n",
      "199   13.4\n"
     ]
    }
   ],
   "source": [
    "#Leave-One-Out cross validation\n",
    "col_include_outnews=['TV','radio']\n",
    "\n",
    "X11_loovc=df[col_include_outnews].reset_index().drop('index', axis=1)\n",
    "\n",
    "y11_loovc=df['sales'].reset_index().drop('index', axis=1)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in loo.split(X11_loovc):\n",
    "    X_train1, X_test1 = X11_loovc.loc[train_index], X11_loovc.loc[test_index]\n",
    "    y_train1, y_test1 = y11_loovc.loc[train_index], y11_loovc.loc[test_index]\n",
    "    print(y_test1)#only one value is selected as test value for every corresponding row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
